{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Avoid duplicate handlers\n",
    "if not logger.handlers:\n",
    "    handler = logging.StreamHandler(sys.stdout)  # stdout works better than stderr in Jupyter\n",
    "    handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))\n",
    "    logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "import lightgbm as lgb\n",
    "import time\n",
    "\n",
    "class BaseModelWrapper:\n",
    "    def __init__(self, model_cls, model_params, name, preprocessor=None):\n",
    "        self.model_cls = model_cls\n",
    "        self.model_params = model_params\n",
    "        self.name = name\n",
    "        self.preprocessor = preprocessor\n",
    "        self.models = []\n",
    "        self.oof_preds = None\n",
    "\n",
    "    def _prep(self, X, fit=False):\n",
    "        return self.preprocessor(X, fit=fit) if self.preprocessor else X\n",
    "\n",
    "    def fit(self, X, y, folds=5):\n",
    "        start_time = time.time()\n",
    "        logger.info(f\"Starting training of {self.name} model with {folds} folds\")\n",
    "        \n",
    "        self.oof_preds = np.zeros(len(X))\n",
    "        self.models = []\n",
    "        kf = KFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X), 1):\n",
    "            fold_start = time.time()\n",
    "            logger.info(f\"Training {self.name} - Fold {fold}/{folds}\")\n",
    "            \n",
    "            X_train = self._prep(X.iloc[train_idx], fit=True)\n",
    "            X_val   = self._prep(X.iloc[val_idx], fit=False)\n",
    "            y_train = y[train_idx]\n",
    "\n",
    "            model = self.model_cls(**self.model_params)\n",
    "            model.fit(X_train, y_train)\n",
    "            self.oof_preds[val_idx] = model.predict(X_val)\n",
    "            self.models.append(model)\n",
    "            \n",
    "            fold_time = time.time() - fold_start\n",
    "            logger.info(f\"Completed {self.name} - Fold {fold}/{folds} in {fold_time:.2f} seconds\")\n",
    "\n",
    "        total_time = time.time() - start_time\n",
    "        logger.info(f\"Completed training of {self.name} model in {total_time:.2f} seconds\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_proc = self._prep(X, fit=False)\n",
    "        preds = [model.predict(X_proc) for model in self.models]\n",
    "        return np.mean(np.column_stack(preds), axis=1)\n",
    "\n",
    "    def retrain_full(self, X, y):\n",
    "        start_time = time.time()\n",
    "        logger.info(f\"Starting full retraining of {self.name} model\")\n",
    "        \n",
    "        X_proc = self._prep(X, fit=True)\n",
    "        model = self.model_cls(**self.model_params)\n",
    "        model.fit(X_proc, y)\n",
    "        self.models = [model]\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        logger.info(f\"Completed full retraining of {self.name} model in {total_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "class StackingEnsembler:\n",
    "    def __init__(self, base_models, meta_model_cls, meta_model_params, meta_preprocessor=None):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model_cls = meta_model_cls\n",
    "        self.meta_model_params = meta_model_params\n",
    "        self.meta_preprocessor = meta_preprocessor\n",
    "        self.meta_model = None\n",
    "\n",
    "    def _prep(self, X, fit=False):\n",
    "        return self.meta_preprocessor(X, fit=fit) if self.meta_preprocessor else X\n",
    "    \n",
    "    def fit(self, X, y, folds=5):\n",
    "        start_time = time.time()\n",
    "        logger.info(f\"Starting stacking ensemble training with {len(self.base_models)} base models\")\n",
    "        \n",
    "        # Train base models and collect OOF predictions\n",
    "        oof_features = []\n",
    "        for i, model in enumerate(self.base_models, 1):\n",
    "            logger.info(f\"Training base model {i}/{len(self.base_models)}: {model.name}\")\n",
    "            model.fit(X, y, folds=folds)\n",
    "            oof_features.append(model.oof_preds.reshape(-1, 1))\n",
    "\n",
    "        logger.info(\"Training meta-model\")\n",
    "        meta_start = time.time()\n",
    "        \n",
    "        meta_X = np.hstack(oof_features)\n",
    "        meta_X = self._prep(meta_X, fit=True)\n",
    "\n",
    "        self.meta_model = self.meta_model_cls(**self.meta_model_params)\n",
    "        self.meta_model.fit(meta_X, y)\n",
    "        \n",
    "        meta_time = time.time() - meta_start\n",
    "        total_time = time.time() - start_time\n",
    "        logger.info(f\"Meta-model training completed in {meta_time:.2f} seconds\")\n",
    "        logger.info(f\"Total stacking ensemble training completed in {total_time:.2f} seconds\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        logger.info(\"Generating predictions from stacking ensemble\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        base_preds = [model.predict(X).reshape(-1, 1) for model in self.base_models]\n",
    "        meta_X = np.hstack(base_preds)\n",
    "        meta_X = self._prep(meta_X, fit=False)\n",
    "        predictions = self.meta_model.predict(meta_X)\n",
    "        \n",
    "        pred_time = time.time() - start_time\n",
    "        logger.info(f\"Predictions generated in {pred_time:.2f} seconds\")\n",
    "        return predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class StandardScalerPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.fitted = False\n",
    "\n",
    "    def __call__(self, X, fit=False):\n",
    "        if fit:\n",
    "            X_scaled = self.scaler.fit_transform(X)\n",
    "            self.fitted = True\n",
    "        else:\n",
    "            if not self.fitted:\n",
    "                raise RuntimeError(\"Preprocessor not fitted\")\n",
    "            X_scaled = self.scaler.transform(X)\n",
    "        return X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_model = BaseModelWrapper(\n",
    "    lgb.LGBMRegressor,\n",
    "    {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'num_leaves': 1024,\n",
    "        'max_bin': 1024,\n",
    "        'learning_rate': 0.02,\n",
    "        'subsample': 0.8,\n",
    "        'n_estimators': 1000,\n",
    "        'verbose': 1\n",
    "    },\n",
    "    name='lgbm'\n",
    ")\n",
    "\n",
    "lasso_model = BaseModelWrapper(\n",
    "    Lasso,\n",
    "    {'alpha': 0.005, 'max_iter': 10000},\n",
    "    preprocessor=StandardScalerPreprocessor(),\n",
    "    name='lasso'\n",
    ")\n",
    "\n",
    "# Now use them in wrappers\n",
    "base_models = [\n",
    "    lgbm_model,\n",
    "    lasso_model,\n",
    "]\n",
    "\n",
    "stack = StackingEnsembler(\n",
    "    base_models=base_models,\n",
    "    meta_model_cls=Ridge,\n",
    "    meta_model_params={'alpha': 0.1},\n",
    "    meta_preprocessor=StandardScalerPreprocessor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train = pd.read_csv('data/train.csv')\n",
    "df_test = pd.read_csv('data/test.csv')\n",
    "\n",
    "# Transform Sex to 0 and 1\n",
    "df_train['Sex'] = df_train['Sex'].map({'male': 0, 'female': 1})\n",
    "df_test['Sex'] = df_test['Sex'].map({'male': 0, 'female': 1})\n",
    "\n",
    "# Transform target (Calories) with log1p\n",
    "df_train['Calories'] = np.log1p(df_train['Calories'])\n",
    "\n",
    "# Create column interactions between all numerical columns\n",
    "numeric_cols = ['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp']\n",
    "\n",
    "# Create interaction features\n",
    "for i in range(len(numeric_cols)):\n",
    "    for j in range(i+1, len(numeric_cols)):\n",
    "        col1, col2 = numeric_cols[i], numeric_cols[j]\n",
    "        interaction_name = f'{col1}_{col2}_interaction'\n",
    "        df_train[interaction_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[interaction_name] = df_test[col1] * df_test[col2]\n",
    "\n",
    "# Prepare features and target\n",
    "X_train = df_train.drop(['Calories', 'id'], axis=1)\n",
    "y_train = df_train['Calories']\n",
    "\n",
    "# Split data into train and validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train level 2 model\n",
    "stack.fit(X_train, y_train, folds=5)\n",
    "\n",
    "# Retrain base models on full data\n",
    "stack.retrain_base_models(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on validation set\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_val_pred = stack.predict(X_val)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = mean_squared_error(y_val, y_val_pred)\n",
    "print(f\"RMSE on validation set: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "\n",
    "# Save ids from test set\n",
    "test_ids = df_test['id']\n",
    "\n",
    "# Remove id column from test set\n",
    "df_test = df_test.drop('id', axis=1)\n",
    "\n",
    "# Predict on test set\n",
    "y_test_pred = stack.predict(df_test)\n",
    "\n",
    "# Inverse transform predictions using expm1\n",
    "y_test_pred = np.expm1(y_test_pred)\n",
    "\n",
    "# Create submission file with ids and predictions\n",
    "submission = pd.DataFrame({'id': test_ids, 'Calories': y_test_pred})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
