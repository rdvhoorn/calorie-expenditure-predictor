{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Avoid duplicate handlers\n",
    "if not logger.handlers:\n",
    "    handler = logging.StreamHandler(sys.stdout)  # stdout works better than stderr in Jupyter\n",
    "    handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))\n",
    "    logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import logging\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Enable GPU logging (set True to see device logs)\n",
    "tf.debugging.set_log_device_placement(False)\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def keras_rmse(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_pred - y_true)))\n",
    "\n",
    "def keras_rmsle(y_true, y_pred):\n",
    "    # Clip predictions to avoid log(0)\n",
    "    y_true = tf.clip_by_value(y_true, 0.0, np.inf)\n",
    "    y_pred = tf.clip_by_value(y_pred, 0.0, np.inf)\n",
    "    \n",
    "    first_log = tf.math.log1p(y_pred)\n",
    "    second_log = tf.math.log1p(y_true)\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(first_log - second_log)))\n",
    "\n",
    "keras_rmsle.__name__ = 'rmsle'  # so Keras logs it nicely\n",
    "\n",
    "keras_rmse.__name__ = 'rmse'  # Required for proper logging in Keras\n",
    "\n",
    "# Wrapper Class\n",
    "class KerasNNWrapper:\n",
    "    def __init__(self, build_fn, metric_fn, name='keras_nn'):\n",
    "        self.build_fn = build_fn\n",
    "        self.name = name\n",
    "        self.metric_fn = metric_fn\n",
    "        self.models = []\n",
    "        self.oof_preds = None\n",
    "\n",
    "    def fit(self, X, y, folds=5, epochs=100, batch_size=1024):\n",
    "        X = X.astype(np.float32)\n",
    "        y = y.values.astype(np.float32) if hasattr(y, 'values') else y.astype(np.float32)\n",
    "\n",
    "        start_time = time.time()\n",
    "        logger.info(f\"Starting training of {self.name} model with {folds} folds\")\n",
    "\n",
    "        self.oof_preds = np.zeros(len(X), dtype=np.float32)\n",
    "        self.models = []\n",
    "        kf = KFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "\n",
    "        # Callbacks\n",
    "        early_stopping = keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss', patience=5, restore_best_weights=True\n",
    "        )\n",
    "        lr_schedule = keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=1e-6\n",
    "        )\n",
    "    \n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X), 1):\n",
    "            fold_start = time.time()\n",
    "            logger.info(f\"Training {self.name} - Fold {fold}/{folds}\")\n",
    "\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "            model = self.build_fn()\n",
    "            model.fit(X_train, y_train,\n",
    "                      validation_data=(X_val, y_val),\n",
    "                      epochs=epochs,\n",
    "                      batch_size=batch_size,\n",
    "                      verbose=2,\n",
    "                      callbacks=[lr_schedule])\n",
    "\n",
    "            preds = model.predict(X_val).flatten()\n",
    "            self.oof_preds[val_idx] = preds\n",
    "            fold_score = self.metric_fn(y_val, preds)\n",
    "            logger.info(f\"Fold {fold} score: {fold_score:.4f}\")\n",
    "\n",
    "            self.models.append(model)\n",
    "            logger.info(f\"Completed {self.name} - Fold {fold} in {time.time() - fold_start:.2f} seconds\")\n",
    "\n",
    "        total_score = self.metric_fn(y, self.oof_preds)\n",
    "        logger.info(f\"Out-of-fold score: {total_score:.4f}\")\n",
    "        logger.info(f\"Completed training of {self.name} in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = X.astype(np.float32)\n",
    "        preds = [model.predict(X).flatten() for model in self.models]\n",
    "        return np.mean(np.column_stack(preds), axis=1)\n",
    "\n",
    "    def retrain_full(self, X, y, epochs=100, batch_size=1024):\n",
    "        X = X.astype(np.float32)\n",
    "        y = y.values.astype(np.float32) if hasattr(y, 'values') else y.astype(np.float32)\n",
    "\n",
    "        start_time = time.time()\n",
    "        logger.info(f\"Starting full retraining of {self.name} model\")\n",
    "\n",
    "        model = self.build_fn()\n",
    "        model.fit(X, y, epochs=epochs, batch_size=batch_size, verbose=2)\n",
    "        self.models = [model]\n",
    "\n",
    "        logger.info(f\"Completed full retraining of {self.name} in {time.time() - start_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "\n",
    "# Transform Sex to 0 and 1\n",
    "df_train['Sex'] = df_train['Sex'].map({'male': 0, 'female': 1})\n",
    "df_test['Sex'] = df_test['Sex'].map({'male': 0, 'female': 1})\n",
    "\n",
    "exclude_cols = ['id', 'Sex', 'Calories']\n",
    "numeric_cols = [col for col in df_train.columns if col not in exclude_cols]\n",
    "# Initialize scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform training data (excluding categorical columns)\n",
    "df_train[numeric_cols] = scaler.fit_transform(df_train[numeric_cols])\n",
    "df_test[numeric_cols] = scaler.transform(df_test[numeric_cols])\n",
    "\n",
    "\n",
    "# Prepare features and target\n",
    "X_train = df_train.drop(['Calories', 'id'], axis=1)\n",
    "y_train = df_train['Calories']\n",
    "\n",
    "# Convert X_train and y_train to float32\n",
    "X_train = X_train.astype(np.float32)\n",
    "y_train = y_train.astype(np.float32)\n",
    "df_test = df_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "\n",
    "# Keras Model Builder\n",
    "def build_model(input_dim):\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(input_dim,)),\n",
    "\n",
    "        layers.Dense(256),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('swish'),\n",
    "        # layers.Dropout(0.2),\n",
    "\n",
    "        layers.Dense(128),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('swish'),\n",
    "        # layers.Dropout(0.2),\n",
    "\n",
    "        layers.Dense(64),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('swish'),\n",
    "        # layers.Dropout(0.2),\n",
    "\n",
    "        layers.Dense(32),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('swish'),\n",
    "\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    optimizer = keras.optimizers.Adam()\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=keras_rmsle\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = KerasNNWrapper(\n",
    "    build_fn=lambda: build_model(input_dim),\n",
    "    metric_fn=keras_rmsle,\n",
    "    name='keras_nn',\n",
    "    )\n",
    "model.fit(X_train, y_train, folds=3, epochs=100, batch_size=3_000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('nn1_oof_preds.npy', model.oof_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the 'id' column before dropping it\n",
    "test_ids = df_test['id']\n",
    "\n",
    "# Drop 'id' column before prediction\n",
    "df_test = df_test.drop('id', axis=1)\n",
    "\n",
    "# Make predictions on test data\n",
    "test_preds = model.predict(df_test)\n",
    "\n",
    "# Create submission file\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'Calories': test_preds\n",
    "})\n",
    "\n",
    "# Save submission file\n",
    "submission.to_csv('submission_nn1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
