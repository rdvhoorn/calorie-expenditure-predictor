{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Avoid duplicate handlers\n",
    "if not logger.handlers:\n",
    "    handler = logging.StreamHandler(sys.stdout)  # stdout works better than stderr in Jupyter\n",
    "    handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "SEED = 42 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "import numpy as np\n",
    "import time\n",
    "import logging\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Metrics\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def rmsle(y_true, y_pred):\n",
    "    y_pred = np.clip(y_pred, 0, None)\n",
    "    y_true = np.clip(y_true, 0, None)\n",
    "    return np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
    "\n",
    "# Linear model wrapper\n",
    "class LinearModelWrapper:\n",
    "    def __init__(self, model_cls=Ridge, model_params=None, metric_fn=rmsle, name=\"ridge_lr\"):\n",
    "        self.model_cls = model_cls\n",
    "        self.model_params = model_params\n",
    "        self.metric_fn = metric_fn\n",
    "        self.name = name\n",
    "        self.models = []\n",
    "        self.oof_preds = None\n",
    "        self.float_type = np.float64\n",
    "\n",
    "    def fit(self, X, y, folds=5):\n",
    "        X = X.astype(self.float_type)\n",
    "        y = y.values.astype(self.float_type) if hasattr(y, 'values') else y.astype(self.float_type)\n",
    "\n",
    "        self.oof_preds = np.zeros(len(X), dtype=self.float_type)\n",
    "        self.models = []\n",
    "        kf = KFold(n_splits=folds, shuffle=True, random_state=SEED)\n",
    "\n",
    "        logger.info(f\"Training {self.name} with {folds}-fold CV\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X), 1):\n",
    "            X_train, X_val = X[train_idx], X[val_idx]\n",
    "            y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "            model = self.model_cls(**self.model_params)\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            preds = model.predict(X_val)\n",
    "            self.oof_preds[val_idx] = preds\n",
    "            fold_score = self.metric_fn(y_val, preds)\n",
    "            logger.info(f\"Fold {fold} {self.metric_fn.__name__.upper()}: {fold_score:.4f}\")\n",
    "            self.models.append(model)\n",
    "\n",
    "        total_score = self.metric_fn(y, self.oof_preds)\n",
    "        logger.info(f\"OOF {self.metric_fn.__name__.upper()}: {total_score:.4f}\")\n",
    "        logger.info(f\"Finished training {self.name} in {time.time() - start_time:.2f}s\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = X.astype(self.float_type)\n",
    "        preds = [model.predict(X) for model in self.models]\n",
    "        return np.mean(np.column_stack(preds), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X has 405 features\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "df_train = pd.read_csv('data/train.csv')\n",
    "df_test = pd.read_csv('data/test.csv')\n",
    "\n",
    "# Transform target (Calories) with log1p\n",
    "# df_train['Calories'] = np.log1p(df_train['Calories'])\n",
    "\n",
    "def feature_engineering(df):\n",
    "    # Create separate columns for male and female\n",
    "    df['Sex_Male'] = (df['Sex'] == 'male').astype(int)\n",
    "    df['Sex_Female'] = (df['Sex'] == 'female').astype(int)\n",
    "    df = df.drop('Sex', axis=1)  # Drop original Sex column\n",
    "\n",
    "    # Add BMI as a feature by dividing weight by height/100 squared, normalized per gender\n",
    "    df['BMI'] = df['Weight'] / ((df['Height']/100) ** 2)\n",
    "    \n",
    "    # Normalize BMI within each gender group\n",
    "    df['BMI_Normalized'] = df.groupby(['Sex_Male', 'Sex_Female'])['BMI'].transform(lambda x: (x - x.mean()) / x.std())\n",
    "\n",
    "    # Encode obesity levels based on BMI\n",
    "    df['BMI_Category'] = pd.cut(df['BMI'], \n",
    "                               bins=[0, 16.5, 18.5, 24.9, 29.9, 34.9, 39.9, float('inf')],\n",
    "                               labels=[0, 1, 2, 3, 4, 5, 6])\n",
    "    \n",
    "\n",
    "    # Exercise intensity (heart rate / duration)\n",
    "    df['Exercise_Intensity'] = df['Heart_Rate'] / df['Duration']\n",
    "\n",
    "    # Heart rate duration\n",
    "    df['Heart_Rate_Duration'] = df['Heart_Rate'] * df['Duration']\n",
    "\n",
    "    # Temperature duration interaction\n",
    "    df['Temp_Duration'] = df['Body_Temp'] * df['Duration']\n",
    "\n",
    "    # HR divided by temp\n",
    "    df['HR_div_Temp'] = df['Heart_Rate'] / df['Body_Temp']\n",
    "\n",
    "    # Weight duration interaction\n",
    "    df['Weight_Duration'] = df['Weight'] * df['Duration']\n",
    "\n",
    "    # Max heart rate (220 - Age)\n",
    "    df['Max_Heart_Rate'] = 220 - df['Age']\n",
    "\n",
    "    # Heart rate intensity (heart rate / max heart rate)\n",
    "    df['Heart_Rate_Intensity'] = df['Heart_Rate'] / df['Max_Heart_Rate']\n",
    "\n",
    "    # Group age into bins\n",
    "    df['Age_Bins'] = pd.cut(df['Age'], bins=[0, 20, 35, 50, 100], labels=[1, 2, 3, 4])\n",
    "\n",
    "    # Get heart rate zones\n",
    "    # Zone 1\tVery Light\t50–60%\n",
    "    # Zone 2\tLight\t60–70%\n",
    "    # Zone 3\tModerate\t70–80%\n",
    "    # Zone 4\tHard\t80–90%\n",
    "    # Zone 5\tMaximum\t90-100%\n",
    "    # Heart rate zone is a percentage of max heart rate\n",
    "    df['HR_Zone'] = pd.cut(df['Heart_Rate_Intensity'] * 100,\n",
    "                          bins=[0, 50, 60, 70, 80, 90, 100],\n",
    "                          labels=[0, 1, 2, 3, 4, 5])\n",
    "    \n",
    "\n",
    "    # Calculate BMR using Mifflin-St Jeor equation with gender-specific constant\n",
    "    df['BMR'] = (10 * df['Weight'] + \n",
    "                 6.25 * df['Height'] - \n",
    "                 5 * df['Age'] +\n",
    "                 5 * df['Sex_Male'] - \n",
    "                 161 * df['Sex_Female'])\n",
    "    \n",
    "    # Add log transformations for skewed features\n",
    "    skewed_feats = ['Age', 'Weight', 'Body_Temp', 'Height', 'Duration', 'Heart_Rate']\n",
    "    for feat in skewed_feats:\n",
    "        df[f'Log_{feat}'] = np.log1p(df[feat])\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply feature engineering to both train and test datasets\n",
    "df_train = feature_engineering(df_train)\n",
    "df_test = feature_engineering(df_test)\n",
    "\n",
    "# Prepare features and target\n",
    "X_train = df_train.drop(['Calories', 'id'], axis=1)\n",
    "y_train = df_train['Calories']\n",
    "\n",
    "# Standard scale X_train\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# Polynomial features on X_train\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train = poly.fit_transform(X_train)\n",
    "\n",
    "# Put it back into a dataframe\n",
    "X_train = pd.DataFrame(X_train, columns=poly.get_feature_names_out())\n",
    "\n",
    "print(f\"X has {X_train.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-11 21:47:30,868 - INFO - Training TTLR with 5-fold CV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Training TTLR with 5-fold CV\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-11 21:48:03,405 - INFO - Fold 1 RMSLE: 0.0603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Fold 1 RMSLE: 0.0603\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompose\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TransformedTargetRegressor\n\u001b[32m      4\u001b[39m linear_model = LinearModelWrapper(\n\u001b[32m      5\u001b[39m     model_cls=TransformedTargetRegressor,\n\u001b[32m      6\u001b[39m     model_params={\u001b[33m'\u001b[39m\u001b[33mregressor\u001b[39m\u001b[33m'\u001b[39m: LinearRegression(), \u001b[33m'\u001b[39m\u001b[33mfunc\u001b[39m\u001b[33m'\u001b[39m: np.log1p, \u001b[33m'\u001b[39m\u001b[33minverse_func\u001b[39m\u001b[33m'\u001b[39m: np.expm1},\n\u001b[32m      7\u001b[39m     metric_fn=rmsle,\n\u001b[32m      8\u001b[39m     name=\u001b[33m'\u001b[39m\u001b[33mTTLR\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      9\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43mlinear_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolds\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 48\u001b[39m, in \u001b[36mLinearModelWrapper.fit\u001b[39m\u001b[34m(self, X, y, folds)\u001b[39m\n\u001b[32m     45\u001b[39m y_train, y_val = y[train_idx], y[val_idx]\n\u001b[32m     47\u001b[39m model = \u001b[38;5;28mself\u001b[39m.model_cls(**\u001b[38;5;28mself\u001b[39m.model_params)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m preds = model.predict(X_val)\n\u001b[32m     51\u001b[39m \u001b[38;5;28mself\u001b[39m.oof_preds[val_idx] = preds\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rvhoo\\Documents\\projects\\calorie-expenditure-predictor\\.venv\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rvhoo\\Documents\\projects\\calorie-expenditure-predictor\\.venv\\Lib\\site-packages\\sklearn\\compose\\_target.py:293\u001b[39m, in \u001b[36mTransformedTargetRegressor.fit\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    290\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    291\u001b[39m     routed_params = Bunch(regressor=Bunch(fit=fit_params))\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mregressor_\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_trans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mregressor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.regressor_, \u001b[33m\"\u001b[39m\u001b[33mfeature_names_in_\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    296\u001b[39m     \u001b[38;5;28mself\u001b[39m.feature_names_in_ = \u001b[38;5;28mself\u001b[39m.regressor_.feature_names_in_\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rvhoo\\Documents\\projects\\calorie-expenditure-predictor\\.venv\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rvhoo\\Documents\\projects\\calorie-expenditure-predictor\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:622\u001b[39m, in \u001b[36mLinearRegression.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    617\u001b[39m \u001b[38;5;66;03m# Note that neither _rescale_data nor the rest of the fit method of\u001b[39;00m\n\u001b[32m    618\u001b[39m \u001b[38;5;66;03m# LinearRegression can benefit from in-place operations when X is a\u001b[39;00m\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# sparse matrix. Therefore, let's not copy X when it is sparse.\u001b[39;00m\n\u001b[32m    620\u001b[39m copy_X_in_preprocess_data = \u001b[38;5;28mself\u001b[39m.copy_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sp.issparse(X)\n\u001b[32m--> \u001b[39m\u001b[32m622\u001b[39m X, y, X_offset, y_offset, X_scale = \u001b[43m_preprocess_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    623\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    625\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy_X_in_preprocess_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n\u001b[32m    631\u001b[39m     \u001b[38;5;66;03m# Sample weight can be implemented via a simple rescaling. Note\u001b[39;00m\n\u001b[32m    632\u001b[39m     \u001b[38;5;66;03m# that we safely do inplace rescaling when _preprocess_data has\u001b[39;00m\n\u001b[32m    633\u001b[39m     \u001b[38;5;66;03m# already made a copy if requested.\u001b[39;00m\n\u001b[32m    634\u001b[39m     X, y, sample_weight_sqrt = _rescale_data(\n\u001b[32m    635\u001b[39m         X, y, sample_weight, inplace=copy_X_in_preprocess_data\n\u001b[32m    636\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rvhoo\\Documents\\projects\\calorie-expenditure-predictor\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:166\u001b[39m, in \u001b[36m_preprocess_data\u001b[39m\u001b[34m(X, y, fit_intercept, copy, copy_y, sample_weight, check_input)\u001b[39m\n\u001b[32m    163\u001b[39m     sample_weight = xp.asarray(sample_weight)\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_input:\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m     X = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43msupported_float_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    169\u001b[39m     y = check_array(y, dtype=X.dtype, copy=copy_y, ensure_2d=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rvhoo\\Documents\\projects\\calorie-expenditure-predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1118\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1115\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[32m   1116\u001b[39m     \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n\u001b[32m   1117\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m np.may_share_memory(array, array_orig):\n\u001b[32m-> \u001b[39m\u001b[32m1118\u001b[39m         array = \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1119\u001b[39m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\n\u001b[32m   1120\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1121\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1122\u001b[39m     \u001b[38;5;66;03m# always make a copy for non-numpy arrays\u001b[39;00m\n\u001b[32m   1123\u001b[39m     array = _asarray_with_order(\n\u001b[32m   1124\u001b[39m         array, dtype=dtype, order=order, copy=\u001b[38;5;28;01mTrue\u001b[39;00m, xp=xp\n\u001b[32m   1125\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rvhoo\\Documents\\projects\\calorie-expenditure-predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:837\u001b[39m, in \u001b[36m_asarray_with_order\u001b[39m\u001b[34m(array, dtype, order, copy, xp, device)\u001b[39m\n\u001b[32m    834\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[32m    835\u001b[39m     \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[32m    836\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m837\u001b[39m         array = \u001b[43mnumpy\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    838\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    839\u001b[39m         array = numpy.asarray(array, order=order, dtype=dtype)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "\n",
    "linear_model = LinearModelWrapper(\n",
    "    model_cls=TransformedTargetRegressor,\n",
    "    model_params={'regressor': LinearRegression(), 'func': np.log1p, 'inverse_func': np.expm1},\n",
    "    metric_fn=rmsle,\n",
    "    name='TTLR'\n",
    ")\n",
    "\n",
    "linear_model.fit(X_train.values, y_train, folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([145.65801656,  36.06555165,  28.99464365, ..., 234.30580657,\n",
       "       106.72924764, 100.13956455], shape=(750000,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.save('lr1_oof_preds.npy', linear_model.oof_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the 'id' column before dropping it\n",
    "test_ids = df_test['id']\n",
    "\n",
    "# Drop 'id' column before prediction\n",
    "df_test = df_test.drop('id', axis=1)\n",
    "\n",
    "X_test = scaler.transform(df_test)\n",
    "\n",
    "X_test = poly.transform(X_test)\n",
    "\n",
    "# Make predictions on test data\n",
    "test_preds = linear_model.predict(X_test)\n",
    "\n",
    "# Create submission file\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'Calories': test_preds\n",
    "})\n",
    "\n",
    "# Save submission file\n",
    "submission.to_csv('data/ensemble/lr1_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
